fp32-training-phase1:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-bert-large-training
  cmd: bash run_model.sh
  shm_size: 16G
  cap_add: 'SYS_NICE'
  env:
    PRECISION: fp32
    BERT_MODEL_CONFIG: /pytorch/bert_squad/config/bert_config.json
    OUTPUT_DIR: /tmp
    TRAIN_SCRIPT: /workspace/pytorch-bert-large-training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/bert_squad/datasets/bert_results4_dataset
    TRAINING_PHASE: '1'
    DDP: 'false'
    TORCH_INDUCTOR: '0'
  volumes:
    - src: /pytorch/bert_squad/config/bert_config.json
      dst: /pytorch/bert_squad/config/bert_config.json
    - src: /tmp
      dst: /tmp
    - src: /pytorch/bert_squad/datasets/bert_results4_dataset
      dst: /pytorch/bert_squad/datasets/bert_results4_dataset
fp32-training-phase2:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-bert-large-training
  cmd: bash run_model.sh
  shm_size: 16G
  cap_add: 'SYS_NICE'
  env:
    PRECISION: fp32
    BERT_MODEL_CONFIG: /pytorch/bert_squad/config/bert_config.json
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /tmp/model_save_fp32
    TRAIN_SCRIPT: /workspace/pytorch-bert-large-training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/bert_squad/datasets/bert_results4_dataset
    TRAINING_PHASE: '2'
    DDP: 'false'
    TORCH_INDUCTOR: '0'
    batch_size: '28'
  volumes:
    - src: /pytorch/bert_squad/config/bert_config.json
      dst: /pytorch/bert_squad/config/bert_config.json
    - src: /tmp/model_save_fp32
      dst: /tmp/model_save_fp32
    - src: /pytorch/bert_squad/datasets/bert_results4_dataset
      dst: /pytorch/bert_squad/datasets/bert_results4_dataset
bf16-training-phase1:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-bert-large-training
  cmd: bash run_model.sh
  shm_size: 16G
  cap_add: 'SYS_NICE'
  env:
    PRECISION: bf16
    BERT_MODEL_CONFIG: /pytorch/bert_squad/config/bert_config.json
    OUTPUT_DIR: /tmp
    TRAIN_SCRIPT: /workspace/pytorch-bert-large-training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/bert_squad/datasets/bert_results4_dataset
    TRAINING_PHASE: '1'
    DDP: 'false'
    TORCH_INDUCTOR: '0'
  volumes:
    - src: /pytorch/bert_squad/config/bert_config.json
      dst: /pytorch/bert_squad/config/bert_config.json
    - src: /tmp
      dst: /tmp
    - src: /pytorch/bert_squad/datasets/bert_results4_dataset
      dst: /pytorch/bert_squad/datasets/bert_results4_dataset
bf16-training-phase2:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-bert-large-training
  cmd: bash run_model.sh
  shm_size: 16G
  cap_add: 'SYS_NICE'
  env:
    PRECISION: bf16
    BERT_MODEL_CONFIG: /pytorch/bert_squad/config/bert_config.json
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /tmp/model_save_bf16
    TRAIN_SCRIPT: /workspace/pytorch-bert-large-training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/bert_squad/datasets/bert_results4_dataset
    TRAINING_PHASE: '2'
    DDP: 'false'
    TORCH_INDUCTOR: '0'
    batch_size: '56'
  volumes:
    - src: /pytorch/bert_squad/config/bert_config.json
      dst: /pytorch/bert_squad/config/bert_config.json
    - src: /tmp/model_save_bf16
      dst: /tmp/model_save_bf16
    - src: /pytorch/bert_squad/datasets/bert_results4_dataset
      dst: /pytorch/bert_squad/datasets/bert_results4_dataset
bf32-training-phase1:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-bert-large-training
  cmd: bash run_model.sh
  shm_size: 16G
  cap_add: 'SYS_NICE'
  env:
    PRECISION: bf32
    BERT_MODEL_CONFIG: /pytorch/bert_squad/config/bert_config.json
    OUTPUT_DIR: /tmp
    TRAIN_SCRIPT: /workspace/pytorch-bert-large-training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/bert_squad/datasets/bert_results4_dataset
    TRAINING_PHASE: '1'
    DDP: 'false'
    TORCH_INDUCTOR: '0'
  volumes:
    - src: /pytorch/bert_squad/config/bert_config.json
      dst: /pytorch/bert_squad/config/bert_config.json
    - src: /tmp
      dst: /tmp
    - src: /pytorch/bert_squad/datasets/bert_results4_dataset
      dst: /pytorch/bert_squad/datasets/bert_results4_dataset
bf32-training-phase2:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-bert-large-training
  cmd: bash run_model.sh
  shm_size: 16G
  cap_add: 'SYS_NICE'
  env:
    PRECISION: bf32
    BERT_MODEL_CONFIG: /pytorch/bert_squad/config/bert_config.json
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /tmp/model_save_bf32
    TRAIN_SCRIPT: /workspace/pytorch-bert-large-training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/bert_squad/datasets/bert_results4_dataset
    TRAINING_PHASE: '2'
    DDP: 'false'
    TORCH_INDUCTOR: '0'
    batch_size: '28'
  volumes:
    - src: /pytorch/bert_squad/config/bert_config.json
      dst: /pytorch/bert_squad/config/bert_config.json
    - src: /tmp/model_save_bf32
      dst: /tmp/model_save_bf32
    - src: /pytorch/bert_squad/datasets/bert_results4_dataset
      dst: /pytorch/bert_squad/datasets/bert_results4_dataset
fp16-training-phase1:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-bert-large-training
  cmd: bash run_model.sh
  shm_size: 16G
  cap_add: 'SYS_NICE'
  env:
    PRECISION: fp16
    BERT_MODEL_CONFIG: /pytorch/bert_squad/config/bert_config.json
    OUTPUT_DIR: /tmp
    TRAIN_SCRIPT: /workspace/pytorch-bert-large-training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/bert_squad/datasets/bert_results4_dataset
    TRAINING_PHASE: '1'
    DDP: 'false'
    TORCH_INDUCTOR: '0'
    DNNL_MAX_CPU_ISA: AVX512_CORE_AMX_FP16
  volumes:
    - src: /pytorch/bert_squad/config/bert_config.json
      dst: /pytorch/bert_squad/config/bert_config.json
    - src: /tmp
      dst: /tmp
    - src: /pytorch/bert_squad/datasets/bert_results4_dataset
      dst: /pytorch/bert_squad/datasets/bert_results4_dataset
fp16-training-phase2:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-bert-large-training
  cmd: bash run_model.sh
  shm_size: 16G
  cap_add: 'SYS_NICE'
  env:
    PRECISION: fp16
    BERT_MODEL_CONFIG: /pytorch/bert_squad/config/bert_config.json
    OUTPUT_DIR: /tmp
    PRETRAINED_MODEL: /tmp/model_save_fp16
    TRAIN_SCRIPT: /workspace/pytorch-bert-large-training/run_pretrain_mlperf.py
    DATASET_DIR: /pytorch/bert_squad/datasets/bert_results4_dataset
    TRAINING_PHASE: '1'
    DDP: 'false'
    TORCH_INDUCTOR: '0'
    batch_size: '28'
    DNNL_MAX_CPU_ISA: AVX512_CORE_AMX_FP16
  volumes:
    - src: /pytorch/bert_squad/config/bert_config.json
      dst: /pytorch/bert_squad/config/bert_config.json
    - src: /tmp/model_save_fp16
      dst: /tmp/model_save_fp16
    - src: /pytorch/bert_squad/datasets/bert_results4_dataset
      dst: /pytorch/bert_squad/datasets/bert_results4_dataset
