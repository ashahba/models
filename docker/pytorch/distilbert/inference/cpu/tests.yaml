fp32-accuracy:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: fp32
    TEST_MODE: ACCURACY
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
fp32-realtime:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: fp32
    TEST_MODE: REALTIME
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '4'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
fp32-throughput:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: fp32
    TEST_MODE: THROUGHPUT
    SEQUENCE_LENGTH: '128'
    BATCH_SIZE: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
bf32-accuracy:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: bf32
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
bf32-realtime:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: bf32
    TEST_MODE: REALTIME
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '4'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
bf32-throughput:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: bf32
    TEST_MODE: THROUGHPUT
    SEQUENCE_LENGTH: '128'
    BATCH_SIZE: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
int8-bf16-accuracy:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: int8-bf16
    TEST_MODE: ACCURACY
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
int8-bf16-realtime:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: int8-bf16
    TEST_MODE: REALTIME
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '4'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
int8-bf16-throughput:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: int8-bf16
    TEST_MODE: THROUGHPUT
    SEQUENCE_LENGTH: '128'
    BATCH_SIZE: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
int8-fp32-accuracy:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: int8-fp32
    TEST_MODE: ACCURACY
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
int8-fp32-realtime:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: int8-fp32
    TEST_MODE: REALTIME
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '4'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
int8-fp32-throughput:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: int8-fp32
    TEST_MODE: THROUGHPUT
    SEQUENCE_LENGTH: '128'
    BATCH_SIZE: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
bf16-accuracy:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: bf16
    TEST_MODE: ACCURACY
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
bf16-realtime:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: bf16
    TEST_MODE: REALTIME
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '4'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
bf16-throughput:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: bf16
    TEST_MODE: THROUGHPUT
    SEQUENCE_LENGTH: '128'
    BATCH_SIZE: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
fp16-realtime:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: fp16
    TEST_MODE: REALTIME
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '4'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
    DNNL_MAX_CPU_ISA: AVX512_CORE_AMX_FP16
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
fp16-throughput:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: fp16
    TEST_MODE: THROUGHPUT
    SEQUENCE_LENGTH: '128'
    BATCH_SIZE: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
    DNNL_MAX_CPU_ISA: AVX512_CORE_AMX_FP16
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
fp16-accuracy:
  img: ${REGISTRY}/aiops/mlops-ci:b-${GITHUB_RUN_NUMBER:-0}-${BASE_IMAGE_NAME:-ubuntu}-${BASE_IMAGE_TAG:-22.04}-language-modeling-distilbert-inference
  cmd: bash run_model.sh
  cap_add: 'SYS_NICE'
  env:
    PRECISION: bf16
    TEST_MODE: ACCURACY
    SEQUENCE_LENGTH: '128'
    CORE_PER_INSTANCE: '32'
    HF_DATASETS_OFFLINE: '0'
    OUTPUT_DIR: /tmp
    FINETUNED_MODEL: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    DATASET_DIR: /pytorch/distilbert_dataset/SST-2/
    DNNL_MAX_CPU_ISA: AVX512_CORE_AMX_FP16
  volumes:
    - src: /pytorch/distilbert_dataset/SST-2/
      dst: /pytorch/distilbert_dataset/SST-2/
    - src: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
      dst: /pytorch/pretrained_models/distilbert/distilbert-base-uncased-finetuned-sst-2-english/
    - src: /tmp
      dst: /tmp
